{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "## Mnist digit classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchvision\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DESCR': 'mldata.org dataset: mnist-original',\n",
       " 'COL_NAMES': ['label', 'data'],\n",
       " 'target': array([0., 0., 0., ..., 9., 9., 9.]),\n",
       " 'data': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = datasets.fetch_mldata('MNIST original', data_home='./data/')\n",
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>774</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9    ...  774  775  776  777  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   778  779  780  781  782  783  \n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize\n",
    "mnist_data = mnist.data / 255\n",
    "pd.DataFrame(mnist_data).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 254,
       "width": 258
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnist_data[0].reshape(28, 28), cmap=cm.gray_r)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 9., 9., 9.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_label = mnist.target\n",
    "mnist_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train dataset, test set split\n",
    "X_train, X_test, y_train, y_test = train_test_split(mnist_data, mnist_label, stratify=mnist_label, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X_train).float()\n",
    "y_train = torch.from_numpy(y_train).long()\n",
    "\n",
    "X_test = torch.from_numpy(X_test).float()\n",
    "y_test = torch.from_numpy(y_test).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([56000, 784])\n",
      "torch.Size([56000])\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate train dataset, dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0118, 0.0000, 0.0118, 0.0275, 0.0745, 0.3569, 0.4196, 0.9569, 0.4314,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1843,\n",
      "        0.7059, 0.8000, 0.7098, 0.8000, 0.9216, 0.9961, 0.9961, 0.9961, 0.9961,\n",
      "        0.7373, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.2588, 0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.9961,\n",
      "        0.9961, 0.7373, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.1412, 0.9686, 0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.9961,\n",
      "        0.9961, 0.9961, 0.7373, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.3804, 0.8235, 0.6157, 0.5098, 0.3059, 0.3686,\n",
      "        0.2706, 0.9451, 0.9961, 0.5804, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.3294, 0.9961, 0.9961, 0.3569, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.1882, 0.9294, 0.9961, 0.7961, 0.0157, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5255, 0.5804, 0.8902, 0.9059,\n",
      "        0.9020, 0.9020, 0.9451, 0.9961, 0.9961, 0.9137, 0.0627, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4314, 0.8824, 0.9961,\n",
      "        0.9882, 0.8157, 0.9961, 0.9961, 0.9490, 0.7059, 0.4431, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0196,\n",
      "        0.0314, 0.3529, 0.6863, 0.9961, 0.9961, 0.4196, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.5843, 1.0000, 0.9961, 0.4275, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.3765, 1.0000, 0.9961, 0.7529, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.1569, 0.9765, 0.9961, 0.7725, 0.1490, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0353, 0.8706, 0.9961, 0.9255, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0392, 0.6902, 0.9961, 0.9961, 0.2314, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.1020, 0.6863, 0.9961, 0.8745, 0.2824, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.7961, 0.9961, 0.9961, 0.2078, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.6235, 0.9804, 0.9961, 0.4941, 0.0078, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.5176, 0.9843, 0.9961, 0.8549, 0.0392, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.4078, 0.9882, 0.9961, 0.8275, 0.2118, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000]), tensor(7))\n"
     ]
    }
   ],
   "source": [
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "\n",
    "print(train_dataset[0])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "        self.fc3 = nn.Linear(256, 256)\n",
    "        self.fc4 = nn.Linear(256, 128)\n",
    "        self.fc5 = nn.Linear(128, 128)\n",
    "        self.fc6 = nn.Linear(128, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc6(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 0.7996124187484384\n",
      "1000 0.11411385098472238\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(1000):\n",
    "    total_loss = 0\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(batch_x)\n",
    "        batch_loss = criterion(output, batch_y)\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += batch_loss.item()\n",
    "        \n",
    "    if (epoch+1) % 500 == 0:\n",
    "        print(epoch+1, total_loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9604285714285714"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test, y_test = Variable(X_test), Variable(y_test)\n",
    "\n",
    "result = torch.max(model(X_test).data, 1)[1]\n",
    "accuracy = sum(y_test.data.numpy()==result.numpy()) / len(y_test.data.numpy())\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_code_all_hidden": true,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
